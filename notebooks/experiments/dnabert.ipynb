{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DNABERT-like Promoter Classifier (PyTorch) - 5 Component Prediction\n",
        "\n",
        "A minimal, self-contained notebook that trains a DNABERT-style classifier on promoter sequences:\n",
        "- Tokenises DNA into overlapping k-mers (k=6 by default)\n",
        "- [CLS] + tokens + [SEP]\n",
        "- Token + positional embeddings\n",
        "- Transformer encoder stack\n",
        "- Classification head on [CLS] to predict 5-component probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
            "    await result\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_72833/1320125903.py\", line 7, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
            "    from pandas.compat import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
            "    from pandas.compat.pyarrow import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
            "    import pyarrow as pa\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
            "    import pyarrow.lib as _lib\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
            "    await result\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_72833/1320125903.py\", line 7, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
            "    from pandas.core.api import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n",
            "    from pandas.core.dtypes.dtypes import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
            "    from pandas._libs import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
            "    import pyarrow.lib as _lib\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
            "    await result\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_72833/1320125903.py\", line 7, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
            "    from pandas.core.api import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
            "    from pandas.core.arrays import Categorical\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
            "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
            "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
            "    from pandas.core import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
            "    from pandas.core.ops.array_ops import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
            "    from pandas.core.computation import expressions\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
            "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
            "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
            "    module = importlib.import_module(name)\n",
            "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
            "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
            "    await result\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_72833/1320125903.py\", line 7, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
            "    from pandas.core.api import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
            "    from pandas.core.arrays import Categorical\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
            "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
            "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
            "    from pandas.core.arrays.masked import BaseMaskedArray\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
            "    from pandas.core import (\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
            "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
            "    module = importlib.import_module(name)\n",
            "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
            "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 2.2.4)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
            "    await result\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_72833/1320125903.py\", line 12, in <module>\n",
            "    from sklearn.model_selection import train_test_split\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 82, in <module>\n",
            "    from .base import clone\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 17, in <module>\n",
            "    from .utils import _IS_32BIT\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 17, in <module>\n",
            "    from scipy.sparse import issparse\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/__init__.py\", line 267, in <module>\n",
            "    from ._csr import *\n",
            "  File \"/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_csr.py\", line 10, in <module>\n",
            "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core.multiarray failed to import",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     21\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/__init__.py:267\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_csr.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[1;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast, get_index_dtype\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import math\n",
        "from itertools import product\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "print(f\"MPS: {getattr(torch.backends, 'mps', None) is not None and torch.backends.mps.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data utilities (inline to keep notebook self-contained)\n",
        "class PromoterDataset(Dataset):\n",
        "    def __init__(self, sequences: list, targets: np.ndarray, max_length: int = 600):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "        self.max_length = max_length\n",
        "        self.dna_dict = {\"A\": 0, \"T\": 1, \"G\": 2, \"C\": 3, \"N\": 4}\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "    def encode_sequence(self, sequence: str) -> np.ndarray:\n",
        "        seq = sequence\n",
        "        if len(seq) > self.max_length:\n",
        "            seq = seq[: self.max_length]\n",
        "        else:\n",
        "            seq = seq + \"N\" * (self.max_length - len(seq))\n",
        "        encoded = np.array([self.dna_dict.get(base.upper(), 4) for base in seq])\n",
        "        one_hot = np.zeros((self.max_length, 5), dtype=np.float32)\n",
        "        one_hot[np.arange(self.max_length), encoded] = 1.0\n",
        "        return one_hot.T\n",
        "    def __getitem__(self, idx: int):\n",
        "        sequence = self.encode_sequence(self.sequences[idx])\n",
        "        target = self.targets[idx].astype(np.float32)\n",
        "        total = float(np.sum(target))\n",
        "        if total <= 0:\n",
        "            target = np.ones_like(target, dtype=np.float32) / target.shape[0]\n",
        "        else:\n",
        "            target = target / total\n",
        "        return {\"sequence\": torch.FloatTensor(sequence), \"target\": torch.FloatTensor(target)}\n",
        "\n",
        "def load_and_prepare_data(file_path: str):\n",
        "    df = pd.read_csv(file_path)\n",
        "    prob_cols = [\"Component_1_Probability\", \"Component_2_Probability\", \"Component_3_Probability\", \"Component_4_Probability\"]\n",
        "    df = df.dropna(subset=[\"ProSeq\"]).dropna(subset=prob_cols)\n",
        "    sequences = df[\"ProSeq\"].tolist()\n",
        "    targets = df[prob_cols].values\n",
        "    valid_sequences = []\n",
        "    valid_targets = []\n",
        "    for i, seq in enumerate(sequences):\n",
        "        if isinstance(seq, str) and len(seq) > 0:\n",
        "            valid_sequences.append(seq)\n",
        "            valid_targets.append(targets[i])\n",
        "    return valid_sequences, np.array(valid_targets, dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DNABERT-like model and tokenisation\n",
        "SPECIALS = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\"]\n",
        "\n",
        "def build_kmer_vocab(k: int):\n",
        "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    kmers = [\"\".join(p) for p in product(bases, repeat=k)]\n",
        "    vocab = SPECIALS + kmers\n",
        "    stoi = {t: i for i, t in enumerate(vocab)}\n",
        "    itos = {i: t for t, i in stoi.items()}\n",
        "    return vocab, stoi, itos\n",
        "\n",
        "def seq_to_kmers(seq: str, k: int) -> List[str]:\n",
        "    seq = seq.upper()\n",
        "    toks: List[str] = []\n",
        "    for i in range(len(seq) - k + 1):\n",
        "        kmer = seq[i:i+k]\n",
        "        if any(c not in \"ACGT\" for c in kmer):\n",
        "            toks.append(\"[UNK]\")\n",
        "        else:\n",
        "            toks.append(kmer)\n",
        "    return [\"[CLS]\"] + toks + [\"[SEP]\"]\n",
        "\n",
        "def encode_batch(seqs: List[str], k: int, stoi: dict, max_len: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    tokenised = [seq_to_kmers(s, k) for s in seqs]\n",
        "    if max_len is None:\n",
        "        max_len = max(len(t) for t in tokenised)\n",
        "    pad_id = stoi[\"[PAD]\"]\n",
        "    unk_id = stoi[\"[UNK]\"]\n",
        "    input_ids = []\n",
        "    attn = []\n",
        "    for toks in tokenised:\n",
        "        ids = [stoi.get(t, unk_id) for t in toks[:max_len]]\n",
        "        mask = [1] * len(ids)\n",
        "        if len(ids) < max_len:\n",
        "            pad_n = max_len - len(ids)\n",
        "            ids += [pad_id] * pad_n\n",
        "            mask += [0] * pad_n\n",
        "        input_ids.append(ids)\n",
        "        attn.append(mask)\n",
        "    return torch.tensor(input_ids, dtype=torch.long), torch.tensor(attn, dtype=torch.bool)\n",
        "\n",
        "def onehot5_to_strings(x: torch.Tensor) -> List[str]:\n",
        "    assert x.ndim == 3 and x.size(1) == 5, \"expected (B,5,L)\"\n",
        "    idx = x.argmax(dim=1)\n",
        "    lut = {0: \"A\", 1: \"T\", 2: \"G\", 3: \"C\", 4: \"N\"}\n",
        "    return [\"\".join(lut[int(i)] for i in row) for row in idx]\n",
        "\n",
        "class DNABertClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        k: int = 6,\n",
        "        num_labels: int = 4,\n",
        "        hidden_size: int = 256,\n",
        "        num_layers: int = 6,\n",
        "        num_heads: int = 8,\n",
        "        ffn_size: Optional[int] = None,\n",
        "        dropout: float = 0.1,\n",
        "        max_position_embeddings: int = 1024,\n",
        "        vocab: Optional[List[str]] = None,\n",
        "        stoi: Optional[dict] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.num_labels = num_labels\n",
        "        if vocab is None or stoi is None:\n",
        "            vocab, stoi, _ = build_kmer_vocab(k)\n",
        "        self.stoi = stoi\n",
        "        self.vocab_size = len(vocab)\n",
        "        if ffn_size is None:\n",
        "            ffn_size = 4 * hidden_size\n",
        "        self.token_embeddings = nn.Embedding(self.vocab_size, hidden_size)\n",
        "        self.pos_embeddings = nn.Embedding(max_position_embeddings, hidden_size)\n",
        "        self.emb_layer_norm = nn.LayerNorm(hidden_size)\n",
        "        self.emb_dropout = nn.Dropout(dropout)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ffn_size,\n",
        "            dropout=dropout,\n",
        "            activation=\"gelu\",\n",
        "            batch_first=True,\n",
        "            norm_first=False,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_labels),\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Linear, nn.Embedding)):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.ones_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        bsz, seqlen = input_ids.shape\n",
        "        device = input_ids.device\n",
        "        if attention_mask is None:\n",
        "            attention_mask = input_ids.ne(self.stoi[\"[PAD]\"])\n",
        "        pos_ids = torch.arange(seqlen, device=device).unsqueeze(0).expand(bsz, seqlen)\n",
        "        x = self.token_embeddings(input_ids) + self.pos_embeddings(pos_ids)\n",
        "        x = self.emb_layer_norm(self.emb_dropout(x))\n",
        "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
        "        cls = x[:, 0]\n",
        "        logits = self.classifier(cls)\n",
        "        return logits\n",
        "\n",
        "def prepare_inputs_from_onehot(onehot_batch: torch.Tensor, k: int, stoi: dict, max_len: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    seqs = onehot5_to_strings(onehot_batch)\n",
        "    input_ids, attn = encode_batch(seqs, k, stoi, max_len=max_len)\n",
        "    return input_ids.to(onehot_batch.device), attn.to(onehot_batch.device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training helpers\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for batch in train_loader:\n",
        "        onehot = batch['sequence'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        input_ids, attn = prepare_inputs_from_onehot(onehot, k=model.k, stoi=model.stoi, max_len=(onehot.shape[-1]-model.k+1)+2)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attn)\n",
        "        log_probs = F.log_softmax(logits, dim=1)\n",
        "        loss = criterion(log_probs, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total / max(1, len(train_loader))\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            onehot = batch['sequence'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            input_ids, attn = prepare_inputs_from_onehot(onehot, k=model.k, stoi=model.stoi, max_len=(onehot.shape[-1]-model.k+1)+2)\n",
        "            logits = model(input_ids, attn)\n",
        "            log_probs = F.log_softmax(logits, dim=1)\n",
        "            loss = criterion(log_probs, targets)\n",
        "            total += loss.item()\n",
        "    return total / max(1, len(val_loader))\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds, targs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            onehot = batch['sequence'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            input_ids, attn = prepare_inputs_from_onehot(onehot, k=model.k, stoi=model.stoi, max_len=(onehot.shape[-1]-model.k+1)+2)\n",
        "            logits = model(input_ids, attn)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            preds.append(probs.cpu().numpy())\n",
        "            targs.append(targets.cpu().numpy())\n",
        "    return np.vstack(preds), np.vstack(targs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5590 1398 1747\n"
          ]
        }
      ],
      "source": [
        "# Load data and build loaders\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "csv_path = \"../../data/processed/ProSeq_with_5component_analysis.csv\"\n",
        "sequences, targets = load_and_prepare_data(csv_path)\n",
        "\n",
        "labels = np.argmax(targets, axis=1)\n",
        "train_seq, test_seq, train_targets, test_targets = train_test_split(\n",
        "    sequences, targets, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "train_labels = np.argmax(train_targets, axis=1)\n",
        "train_seq, val_seq, train_targets, val_targets = train_test_split(\n",
        "    train_seq, train_targets, test_size=0.2, random_state=42, stratify=train_labels\n",
        ")\n",
        "\n",
        "train_ds = PromoterDataset(train_seq, train_targets)\n",
        "val_ds = PromoterDataset(val_seq, val_targets)\n",
        "test_ds = PromoterDataset(test_seq, test_targets)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(len(train_ds), len(val_ds), len(test_ds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on mps...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     tr = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     va = validate_epoch(model, val_loader, criterion, device)\n\u001b[32m     23\u001b[39m     scheduler.step(va)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      7\u001b[39m onehot = batch[\u001b[33m'\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m      8\u001b[39m targets = batch[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m input_ids, attn = \u001b[43mprepare_inputs_from_onehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43monehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstoi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43monehot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m-\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m     11\u001b[39m logits = model(input_ids, attn)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mprepare_inputs_from_onehot\u001b[39m\u001b[34m(onehot_batch, k, stoi, max_len)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_inputs_from_onehot\u001b[39m(onehot_batch: torch.Tensor, k: \u001b[38;5;28mint\u001b[39m, stoi: \u001b[38;5;28mdict\u001b[39m, max_len: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     seqs = \u001b[43monehot5_to_strings\u001b[49m\u001b[43m(\u001b[49m\u001b[43monehot_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     input_ids, attn = encode_batch(seqs, k, stoi, max_len=max_len)\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m input_ids.to(onehot_batch.device), attn.to(onehot_batch.device)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36monehot5_to_strings\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     44\u001b[39m idx = x.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m lut = {\u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m3\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlut\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     44\u001b[39m idx = x.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m lut = {\u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m3\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(lut[\u001b[38;5;28mint\u001b[39m(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m idx]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     44\u001b[39m idx = x.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m lut = {\u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m3\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(lut[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m idx]\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train DNABERT-like model\n",
        "if getattr(torch.backends, 'mps', None) is not None and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = DNABertClassifier(k=6, num_labels=5, hidden_size=256, num_layers=6, num_heads=8, max_position_embeddings=1024)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=8, factor=0.5)\n",
        "\n",
        "num_epochs = 30\n",
        "train_losses, val_losses = [], []\n",
        "best_val = float('inf')\n",
        "bad_epochs = 0\n",
        "max_bad_epochs = 10\n",
        "print(f\"Training on {device}...\")\n",
        "for epoch in range(num_epochs):\n",
        "    tr = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    va = validate_epoch(model, val_loader, criterion, device)\n",
        "    scheduler.step(va)\n",
        "    train_losses.append(tr)\n",
        "    val_losses.append(va)\n",
        "    if va < best_val - 1e-6:\n",
        "        best_val = va\n",
        "        bad_epochs = 0\n",
        "        torch.save(model.state_dict(), 'best_dnabert_like.pth')\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= max_bad_epochs:\n",
        "            print(f\"Early stop at epoch {epoch+1}\")\n",
        "            break\n",
        "    print(f\"Epoch {epoch+1:03d}/{num_epochs} - train {tr:.6f} - val {va:.6f} - lr {optimizer.param_groups[0]['lr']:.2e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Evaluation and quick plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# reload best\n",
        "model.load_state_dict(torch.load('best_dnabert_like.pth', map_location=device))\n",
        "\n",
        "predictions, true_targets = evaluate_model(model, test_loader, device)\n",
        "\n",
        "component_names = ['Component_1', 'Component_2', 'Component_3', 'Component_4', 'Component_5']\n",
        "metrics = {}\n",
        "for i, name in enumerate(component_names):\n",
        "    mse = mean_squared_error(true_targets[:, i], predictions[:, i])\n",
        "    r2 = r2_score(true_targets[:, i], predictions[:, i])\n",
        "    metrics[name] = {'MSE': float(mse), 'R2': float(r2)}\n",
        "\n",
        "overall_mse = mean_squared_error(true_targets, predictions)\n",
        "overall_r2 = r2_score(true_targets.flatten(), predictions.flatten())\n",
        "metrics['Overall'] = {'MSE': float(overall_mse), 'R2': float(overall_r2)}\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "# basic training curve\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(val_losses, label='val')\n",
        "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss'); plt.title('DNABERT-like training'); plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Single-sequence prediction helper\n",
        "def predict_component_probabilities_dnabert(model: DNABertClassifier, sequence: str, device):\n",
        "    model.eval()\n",
        "    seqs = [sequence]\n",
        "    max_len = (len(sequence)-model.k+1)+2 if len(sequence) >= model.k else model.k+2\n",
        "    input_ids, attn = encode_batch(seqs, model.k, model.stoi, max_len=max_len)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attn = attn.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attn)\n",
        "        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "    pred_comp = int(np.argmax(probs) + 1)\n",
        "    conf = float(np.max(probs))\n",
        "    return {\n",
        "        'component_1_prob': float(probs[0]),\n",
        "        'component_2_prob': float(probs[1]),\n",
        "        'component_3_prob': float(probs[2]),\n",
        "        'component_4_prob': float(probs[3]),\n",
        "        'predicted_component': pred_comp,\n",
        "        'confidence': conf,\n",
        "    }\n",
        "\n",
        "# Example\n",
        "sample = sequences[0]\n",
        "print(predict_component_probabilities_dnabert(model, sample, device))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
