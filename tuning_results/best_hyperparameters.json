{
  "depth": 4,
  "base_channels": 24,
  "dropout": 0.1,
  "learning_rate": 0.001,
  "weight_decay": 0.0001,
  "optimizer": "adamw",
  "scheduler": "cosine",
  "loss_function": "mse",
  "gradient_accumulation_steps": 2,
  "batch_size": 512,
  "effective_batch_size": 2048
}